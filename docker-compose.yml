services:
  transcription-corrector:
    build: .
    ports:
      - "8081:8081"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - API_HOST=${API_HOST:-0.0.0.0}
      - API_PORT=${API_PORT:-8081}
    env_file:
      - .env
    volumes:
      - .:/app
    restart: unless-stopped
    # использование nvidia gpu и рантайма
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  transcription-corrector-openai:
    build: .
    ports:
      - "8082:8081"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - API_HOST=${API_HOST:-0.0.0.0}
      - API_PORT=${API_PORT:-8081}
    env_file:
      - .env
    volumes:
      - .:/app
    command: ["uvicorn", "mainOpenAI:app", "--host", "0.0.0.0", "--port", "8081"]
    restart: unless-stopped

  client-app:
    build: .
    ports:
      - "7860:7860"
    environment:
      - LOCAL_API_URL=${LOCAL_API_URL:-http://transcription-corrector:8081}
      - OPENAI_API_URL=${OPENAI_API_URL:-http://transcription-corrector-openai:8081}
    env_file:
      - .env
    volumes:
      - .:/app
    command: ["python", "client_app_combined.py"]
    restart: unless-stopped
    depends_on:
      - transcription-corrector
      - transcription-corrector-openai 