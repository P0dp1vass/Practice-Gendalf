# Transcription Corrector (fork)

Система коррекции текста с поддержкой локальной модели и OpenAI API.

В рамках практики разработана система для автоматической коррекции текста, которая состоит из двух основных компонентов. Первый — это API, реализованный с помощью FastAPI. Второй компонент — это пользовательский интерфейс Gradio.

Проект реализован с двумя отдельными FastAPI серверами: один обрабатывает текст с помощью локальной модели на базе трансформера T5, дополненной библиотеками Natasha и Silero для морфологического анализа и восстановления пунктуации; второй сервер работает с OpenAI API, предоставляя альтернативный способ коррекции текста через облачную модель. Пользовательский интерфейс Gradio объединяет эти два варианта, позволяя пользователю выбирать, какую модель использовать для коррекции текста — локальную или OpenAI.

## Быстрый старт с Docker Compose

### 1. Подготовка окружения

Скопируйте файл конфигурации:
```bash
cp env.example .env
```

Отредактируйте `.env` файл, добавив ваш OpenAI API ключ:
```
OPENAI_API_KEY=your_actual_openai_api_key_here
```

### 2. Запуск через Docker Compose

```bash
docker-compose up --build
```

### 3. Использование

После запуска доступны следующие сервисы:

- **Основной API (локальная модель)**: http://localhost:8081
- **OpenAI API**: http://localhost:8082  
- **Веб-интерфейс**: http://localhost:7860

## Структура проекта

- `main.py` - Основной API с локальной моделью
- `mainOpenAI.py` - API с использованием OpenAI
- `corrector.py` - Логика коррекции текста
- `client_app.py` - Простой веб-интерфейс
- `client_app_combined.py` - Веб-интерфейс с выбором модели
- `docker-compose.yml` - Конфигурация Docker Compose
- `env.example` - Пример файла конфигурации

## Переменные окружения

| Переменная | Описание | По умолчанию |
|-----------|----------|-------------|
| `OPENAI_API_KEY` | API ключ OpenAI | - |
| `API_HOST` | Хост для API | 0.0.0.0 |
| `API_PORT` | Порт для API | 8081 |
| `LOCAL_API_URL` | URL локального API | http://transcription-corrector:8081 |
| `OPENAI_API_URL` | URL OpenAI API | http://transcription-corrector-openai:8081 |
| `USE_SILERO_TE` | Включение/отключение Silero Text Enhancement | true |

## Локальная разработка

Для локальной разработки используйте переменные окружения:
```bash
export LOCAL_API_URL=http://localhost:8081
export OPENAI_API_URL=http://localhost:8082
```

## API Endpoints

### POST /submit
Отправка текста на коррекцию
```json
{
  "text": "текст с ошибками"
}
```

### GET /result/{task_id}
Получение результата коррекции
```json
{
  "status": "done",
  "result": {
    "corrected_text": "исправленный текст",
    "corrections": {"ошибка": "исправление"},
    "precision": 0.95
  }
}
```

## Технические детали проекта

Архитектура проекта состоит из трёх основных частей:

- FastAPI отвечает за создание REST API, который принимает текстовые данные, запускает алгоритмы коррекции и возвращает результаты.

- Gradio обеспечивает удобный пользовательский интерфейс для взаимодействия с API, позволяя вводить текст и получать исправления в режиме реального времени.

Для обработки текста локально используется модель трансформеров T5 (модель UrukHan/t5-russian-spell), обученная на задаче исправления орфографических ошибок в русском языке. Кроме того, применены библиотеки Natasha для морфологического анализа и нормализации слов, а также Silero для восстановления пунктуации и заглавных букв. Для токенизации текста используется nltk с ресурсом punkt, а для оценки схожести слов — алгоритм Левенштейна (Levenshtein), который позволяет находить наиболее вероятные исправления.

## Кэширование моделей

В Docker Compose настроены следующие named volumes для кэширования моделей:

- `huggingface_cache` - для кэширования Hugging Face моделей (T5 модель: `UrukHan/t5-russian-spell`)
- `torch_hub_cache` - для кэширования PyTorch Hub моделей (Silero модель: `snakers4/silero-models`)
- `nltk_data` - для кэширования NLTK данных (punkt tokenizer)

Это значительно ускоряет повторные запуски контейнеров, так как модели не загружаются заново каждый раз. Модели автоматически кэшируются в соответствующих директориях:
- `/root/.cache/huggingface` - для Hugging Face моделей
- `/root/.cache/torch` - для PyTorch Hub моделей
- `/root/nltk_data` - для NLTK данных

## Обработка проблемных текстов

Silero Text Enhancement может работать нестабильно с неструктурированными текстами, содержащими:
- Временные метки (например, `[0:00:30]`, `[0,01,13]`)
- Метки спикеров (например, `Спикер No1`)
- Артефакты транскрипции
- Большое количество специальных символов

Для таких случаев система автоматически определяет проблемные тексты и пропускает этап Text Enhancement, или вы можете полностью отключить его через переменную окружения `USE_SILERO_TE=false`.
